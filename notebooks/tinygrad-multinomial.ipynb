{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"DEBUG\"] = \"1\"\n",
    "\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.helpers import dtypes\n",
    "from tinygrad.ops import Device\n",
    "Device.DEFAULT = \"CPU\"\n",
    "\n",
    "import numpy as np\n",
    "from typing import List, Dict, Tuple, Union, Optional\n",
    "import math\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps\n",
    "\n",
    "1. Learn about the multinomial distribution\n",
    "2. experiment with torch.multinomial\n",
    "   1. only takes ndim = 1 or 2\n",
    "3. write some psuedocode for tinygrad\n",
    "4. get a brute force implementation working with tinygrad\n",
    "5. write tests\n",
    "6. optimize\n",
    "\n",
    "\n",
    "### What is the multinomial distribution?\n",
    "A generalization of the binomial distribution, there are $n$ trials and each trial results in one of $k$ possible outcomes, with each outcome having a cerain probability.\n",
    "- in each of the $n$ trials, one of $k$ outcomes occurs\n",
    "- the probability of each outcome is specified by a vector $\\vec{p}$ of length $k$, where the sum of the elements of $\\vec{p}$ is 1 (as it is a probability distribution)\n",
    "- the resulting distribution gives the probability of each combinaiton of outcomes over all $n$ trials\n",
    "\n",
    "### Pytorch's Implementation\n",
    "\n",
    "\n",
    "### Psuedocode\n",
    "\n",
    "```\n",
    "- input\n",
    "    - input tensor (ndim=1 or ndim=2)\n",
    "    - n is the number of samples to draw\n",
    "    - replacement (bool) whether to draw with replacement or not\n",
    "- validate input\n",
    "    - make sure input is a tensor of ndim=1 or ndim=2, else raise error\n",
    "    - make sure there's no negative values in the input tensor, else raise error\n",
    "    - make sure there are no null values in the input tensor, else raise error\n",
    "    - make sure the sum of the input tensor is 1, else raise error (or normalize it)\n",
    "- errors\n",
    "    - if replacement is False, and n > k (len of input tensor), raise error \n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's play with torch multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.multinomial(input, num_samples, replacement=False, *, generator=None, out=None) â†’ LongTensor\n",
    "\n",
    "#  Returns a tensor where each row contains num_samples indices sampled from the multinomial probability distribution\n",
    "#  located in the corresponding row of tensor input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0, 0, 1])\n",
      "tensor([[1, 2, 1, 2, 1],\n",
      "        [0, 0, 1, 1, 2]])\n"
     ]
    }
   ],
   "source": [
    "example_1d = torch.tensor([.2, .4, .4])\n",
    "example_1d_multinomial = torch.multinomial(example_1d, 3, replacement=True)\n",
    "print(example_1d_multinomial)\n",
    "\n",
    "example_2d = torch.tensor([[.2, .4, .4], [.3, .3, .4]])\n",
    "example_2d_multinomial = torch.multinomial(example_2d, 5, replacement=True)\n",
    "print(example_2d_multinomial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at the old PR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def choice(a: Union[Tensor, int], size: Union[int, Tuple[int, ...]] = 1, p: Optional[Tensor] = None):\n",
    "    if isinstance(a, int): a = Tensor.arange(a)\n",
    "    assert isinstance(a, Tensor) and a.ndim == 1, \"a must be 1-dimensional\"\n",
    "    if p is not None:\n",
    "        assert a.shape == p.shape, \"a and p must have the same shape\"\n",
    "    else:\n",
    "        p = Tensor.full(a.shape, 1 / a.numel())\n",
    "    size = (size,) if isinstance(size, int) else size\n",
    "    cdf = p.cumsum()\n",
    "    cdf /= cdf[-1] # probabilities should sum to 1\n",
    "    unif_samples = Tensor.rand(n_samples := math.prod(size), 1)\n",
    "    indices = (unif_samples.expand(n_samples, a.numel()) >= cdf).sum(1).cast(dtypes.int32)\n",
    "    return a[indices].reshape(size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Psuedocode\n",
    "\n",
    "```\n",
    "- input\n",
    "    - input tensor (ndim=1 or ndim=2)\n",
    "    - n is the number of samples to draw\n",
    "    - replacement (bool) whether to draw with replacement or not\n",
    "- validate input\n",
    "    - make sure input is a tensor of ndim=1 or ndim=2, else raise error\n",
    "    - make sure there's no negative values in the input tensor, else raise error\n",
    "    - make sure there are no null values in the input tensor, else raise error\n",
    "    - make sure the sum of the input tensor is 1, else raise error (or normalize it - pytorch does not automatically normalize i think)\n",
    "- errors\n",
    "    - if replacement is False, and n > k (len of input tensor), raise error \n",
    "```\n",
    "\n",
    "```\n",
    "function multinomial(input_tensor, n_samples, replacement)\n",
    "    validate input\n",
    "    check replacement logic, raise error if necessary\n",
    "\n",
    "    if 2D tensor, iterate over each row:\n",
    "        normalize if necessary\n",
    "        calculate the CDF\n",
    "        get the random numbers\n",
    "        convert the random numbers to indices based on the CDF\n",
    "        return the indices\n",
    "    else if 1D tensor:\n",
    "        normalize if necessary\n",
    "        calculate the CDF\n",
    "        get the random numbers\n",
    "        convert the random numbers to indices based on the CDF\n",
    "        return the indices\n",
    "```\n",
    "\n",
    "```\n",
    "multinomial(input_tensor, n_samples, replacement)\n",
    "    validation logic\n",
    "    replacment logic\n",
    "    def multinomial_1d(input_tensor of ndim=1, n_samples, replacement)\n",
    "        normalize if necessary\n",
    "        calculate the CDF\n",
    "        get the random numbers\n",
    "        convert the random numbers to indices based on the CDF\n",
    "        return the indices\n",
    "\n",
    "    if 2d:\n",
    "        for each row:\n",
    "            multinomial_1d(row, n_samples, replacement)\n",
    "    else:\n",
    "        multinomial_1d(input_tensor, n_samples, replacement)\n",
    "\n",
    "    return the indices\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "@staticmethod\n",
    "def multinomial(input: Tensor, num_samples: int, replacement: bool = False):\n",
    "    assert isinstance(input, Tensor) and (input.ndim == 1 or input.ndim == 2), \"input must be a 1 or 2-dimensional tensor\"\n",
    "    assert isinstance(num_samples, int) and num_samples > 0, \"num_samples must be a positive integer\"\n",
    "    if replacement == False:\n",
    "        assert num_samples <= input.numel(), f\"num_samples: {num_samples} must be less than or equal to the number of elements in input tensor: {input.numel()}\"\n",
    "        # TODO: implement without replacement\n",
    "        raise NotImplementedError(\"multinomial without replacement not implemented\")\n",
    "    \n",
    "    input = input.reshape(-1, 1) if input.ndim == 1 else input # handling 1D and 2d input uniformly\n",
    "    \n",
    "    cdf = input.cumsum() # cumulative distribution function\n",
    "    cdf /= cdf[:, -1, None] # normalize each row of cdf to sum to 1)\n",
    "    unif_samples = Tensor.rand(num_samples, 1) if input.ndim == 1 else Tensor.rand(input.shape[0], num_samples, 1)\n",
    "    cdf_expanded = cdf.unsqueeze(-1) if input.ndim == 1 else cdf.unsqueeze(2) # Expanding dimensions for broadcasting\n",
    "    # Broadcasting comparison\n",
    "    indices = (unif_samples >= cdf_expanded).sum(dim=-1) - 1\n",
    "    indices = indices.cast(dtypes.int32)\n",
    "\n",
    "\n",
    "    # rest of logic here\n",
    "    return indices.flatten() if input.ndim == 1 else indices\n",
    "\n",
    "Tensor.multinomial = multinomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.5        1.         1.        ]\n",
      " [0.625      0.87500006 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Let's make test cases and play with the logic/try to clean it up. can use pytorch for help\n",
    "p_1d = Tensor([.2, .2, .4])\n",
    "p_2d = Tensor([[.2, .4, .4], [.3, .3, .4]])\n",
    "p_3d = Tensor([[[.2, .4, .4], [.3, .3, .4]], [[.2, .4, .4], [.3, .3, .4]]])\n",
    "\n",
    "num_samples = 5\n",
    "replacement = True\n",
    "\n",
    "cdf_1d = p_1d.cumsum() \n",
    "cdf_1d /= cdf_1d[-1] # probabilities should sum to 1\n",
    "assert cdf_1d[-1] == 1, \"probabilities should sum to 1\"\n",
    "# print(cdf_1d.numpy())\n",
    "\n",
    "cdf_2d = p_2d.cumsum()\n",
    "cdf_2d /= cdf_2d[:, -1, None] # normalize each row of cdf to sum to 1)\n",
    "assert all(cdf_2d[:, -1] == 1), \"probabilities should sum to 1\"\n",
    "print(cdf_2d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.25 0.5  1.  ]\n",
      "[[0.32764024]\n",
      " [0.5309934 ]\n",
      " [0.9486966 ]\n",
      " [0.5760423 ]\n",
      " [0.1702497 ]]\n",
      "[1. 2. 2. 2. 0.]\n"
     ]
    }
   ],
   "source": [
    "# 1D case\n",
    "p_1d = Tensor([.2, .2, .4])\n",
    "num_samples = 5\n",
    "\n",
    "def _1D(input: Tensor, num_samples: int, replacement=False):\n",
    "    assert input.ndim == 1, \"only takes 1d input\"\n",
    "    cdf = input.cumsum()\n",
    "    cdf /= cdf[-1] # probabilities should sum to 1\n",
    "    unif_samples = Tensor.rand(num_samples, 1) # uniform samples\n",
    "    indices = (unif_samples >= cdf).sum(1) # find the first index where the unif_samples are greater than the cdf\n",
    "\n",
    "\n",
    "cdf_1d = p_1d.cumsum()\n",
    "cdf_1d /= cdf_1d[-1] # probabilities should sum to 1\n",
    "print(cdf_1d.numpy())\n",
    "unif_samples = Tensor.rand(num_samples, 1)\n",
    "print(unif_samples.numpy())\n",
    "# find the first index where the unif_samples are greater than the cdf\n",
    "indices = (unif_samples >= cdf_1d).sum(1)\n",
    "print(indices.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3, 6])\n",
      "tensor([[0.3333, 0.6667, 1.0000],\n",
      "        [0.6667, 0.8333, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "print(matrix[:, -1]) # last el of each row\n",
    "# get each row\n",
    "# take the matrix and divide each row by the last element in the row\n",
    "print(matrix / matrix[:, -1, None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2        0.6        0.70000005 1.        ]\n"
     ]
    }
   ],
   "source": [
    "t = Tensor([.2, .4, .1, .3])\n",
    "cdf = t.cumsum()\n",
    "print(cdf.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0]\n",
      " [0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "t = Tensor([[0.1, 0.2, 0.3, 0.4], [0.4, 0.3, 0.2, 0.1]])\n",
    "print(t.multinomial(5, replacement=True).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = Tensor.rand(3, 4)\n",
    "res = t.multinomial(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n",
      "(4,)\n"
     ]
    }
   ],
   "source": [
    "t = Tensor.rand(3,4)\n",
    "for i in range(t.shape[0]):\n",
    "    row = t[i]\n",
    "    print(row.shape)\n",
    "    row_prob = row / row.sum()\n",
    "    print(row_prob.shape)\n",
    "    cum_dist = row_prob.cumsum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
