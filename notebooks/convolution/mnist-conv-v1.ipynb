{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEBUG'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn.optim import SGD\n",
    "from tinygrad.nn import Conv2d, BatchNorm2d, Linear\n",
    "from tinygrad.nn.state import get_parameters\n",
    "\n",
    "from lib.utils import get_mnist\n",
    "from lib.dataloader import SimpleDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_mnist(\"../../data\") # these need to be tensors??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets build and test with tinygrad's built in methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock:\n",
    "    def __init__(self, input_channels, output_channels, kernel_size):\n",
    "        self.conv_layer = Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.batch_norm_layer = BatchNorm2d(output_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv_layer(x) # (batch_size, 28, 28, 1) -> (batch_size, 26, 26, 32)\n",
    "        x = self.batch_norm_layer(x).relu()\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x): return self.forward(x)\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        return get_parameters(self.conv_layer) + get_parameters(self.batch_norm_layer)\n",
    "\n",
    "class TinyConv:\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvBlock(1, 32, 3)  # (batch_size, 1, 28, 28) -> (batch_size, 32, 26, 26)\n",
    "        self.conv2 = ConvBlock(32, 64, 3)  # (batch_size, 32, 13, 13) -> (batch_size, 64, 11, 11)\n",
    "        self.fc1 = Linear(64 * 5 * 5, 128)  # (batch_size, 1600) -> (batch_size, 128)\n",
    "        self.fc2 = Linear(128, 10)  # (batch_size, 128) -> (batch_size, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.reshape(-1, 1, 28, 28)  # (batch_size, 784) -> (batch_size, 1, 28, 28)\n",
    "        x = self.conv1(x)  # (batch_size, 1, 28, 28) -> (batch_size, 32, 26, 26)\n",
    "        x = x.max_pool2d(kernel_size=(2,2))  # (batch_size, 32, 26, 26) -> (batch_size, 32, 13, 13)\n",
    "        x = self.conv2(x)  # (batch_size, 32, 13, 13) -> (batch_size, 64, 11, 11)\n",
    "        x = x.max_pool2d(kernel_size=(2,2))  # (batch_size, 64, 11, 11) -> (batch_size, 64, 5, 5)\n",
    "        x = x.reshape(x.shape[0], -1)  # (batch_size, 64, 5, 5) -> (batch_size, 1600)\n",
    "        x = self.fc1(x).relu()  # (batch_size, 1600) -> (batch_size, 128)\n",
    "        x = self.fc2(x).softmax()  # (batch_size, 128) -> (batch_size, 10)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x): return self.forward(x)\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        return get_parameters(self.conv1) + get_parameters(self.conv2) + get_parameters(self.fc1) + get_parameters(self.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SimpleDataLoader(X_train, Y_train, batch_size=64, shuffle=True)\n",
    "test_loader = SimpleDataLoader(X_test, Y_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyConv()\n",
    "optim = SGD(model.parameters(), lr=0.001) # instantiate the optimizer\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS = 100 # num of batches per epoch\n",
    "BATCH_SIZE = 64\n",
    "max_batches_per_epoch = math.ceil(len(X_train) / BATCH_SIZE) # handle smaller last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10: 100 Batches (max: 782) | Train Loss: 2.2986 | Test Accuracy: 0.1563 | Time: 14.57s\n",
      "Epoch 2/10: 100 Batches (max: 782) | Train Loss: 2.2945 | Test Accuracy: 0.2095 | Time: 13.45s\n"
     ]
    }
   ],
   "source": [
    "total_time = 0.0\n",
    "steps = min(STEPS, max_batches_per_epoch)\n",
    "for epoch in range(EPOCHS):\n",
    "    start = perf_counter()\n",
    "    running_train_loss = 0.0\n",
    "    for step in range(steps):\n",
    "        with Tensor.train():\n",
    "            samp = np.random.randint(0, X_train.shape[0], size=(64))\n",
    "\n",
    "            # get batch and labels\n",
    "            batch = Tensor(X_train[samp], requires_grad=False)\n",
    "            labels = Tensor(Y_train[samp])\n",
    "\n",
    "            out = model(batch) # forward pass\n",
    "            loss = out.sparse_categorical_crossentropy(labels) # calculate loss\n",
    "            optim.zero_grad() # zero out gradients\n",
    "            loss.backward() # backward pass\n",
    "            optim.step() # update weights\n",
    "\n",
    "            running_train_loss += loss.numpy()\n",
    "\n",
    "    train_loss = running_train_loss / STEPS # loss over all batches, over num batches\n",
    "\n",
    "    # test accuracy over the whole dataset\n",
    "    out = model(Tensor(X_test))\n",
    "    pred = out.argmax(axis=1) # get the index of the max value\n",
    "    accuracy = (pred == Tensor(Y_test)).mean().numpy()\n",
    "\n",
    "    elapsed = perf_counter() - start\n",
    "    total_time += elapsed\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: {steps} Batches (max: {max_batches_per_epoch}) | Train Loss: {train_loss:.4f} | Test Accuracy: {accuracy:.4f} | Time: {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
