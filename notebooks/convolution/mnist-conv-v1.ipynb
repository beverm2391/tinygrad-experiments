{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEBUG'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn.optim import SGD\n",
    "from tinygrad.nn import Conv2d, BatchNorm2d, Linear\n",
    "from tinygrad.nn.state import get_parameters\n",
    "\n",
    "from lib.utils import get_mnist\n",
    "from lib.dataloader import SimpleDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_mnist(\"../../data\") # these need to be tensors??"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, lets build and test with tinygrad's built in methods\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock:\n",
    "    def __init__(self, input_channels, output_channels, kernel_size):\n",
    "        self.conv_layer = Conv2d(input_channels, output_channels, kernel_size)\n",
    "        self.batch_norm_layer = BatchNorm2d(output_channels)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = self.conv_layer(x) # (batch_size, 28, 28, 1) -> (batch_size, 26, 26, 32)\n",
    "        x = self.batch_norm_layer(x).relu()\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x): return self.forward(x)\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        return get_parameters(self.conv_layer) + get_parameters(self.batch_norm_layer)\n",
    "\n",
    "class TinyConv:\n",
    "    def __init__(self):\n",
    "        self.conv1 = ConvBlock(1, 32, 3)  # (batch_size, 1, 28, 28) -> (batch_size, 32, 26, 26)\n",
    "        self.conv2 = ConvBlock(32, 64, 3)  # (batch_size, 32, 13, 13) -> (batch_size, 64, 11, 11)\n",
    "        self.fc1 = Linear(64 * 5 * 5, 128)  # (batch_size, 1600) -> (batch_size, 128)\n",
    "        self.fc2 = Linear(128, 10)  # (batch_size, 128) -> (batch_size, 10)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        x = x.reshape(-1, 1, 28, 28)  # (batch_size, 784) -> (batch_size, 1, 28, 28)\n",
    "        x = self.conv1(x)  # (batch_size, 1, 28, 28) -> (batch_size, 32, 26, 26)\n",
    "        x = x.max_pool2d(kernel_size=(2,2))  # (batch_size, 32, 26, 26) -> (batch_size, 32, 13, 13)\n",
    "        x = self.conv2(x)  # (batch_size, 32, 13, 13) -> (batch_size, 64, 11, 11)\n",
    "        x = x.max_pool2d(kernel_size=(2,2))  # (batch_size, 64, 11, 11) -> (batch_size, 64, 5, 5)\n",
    "        x = x.reshape(x.shape[0], -1)  # (batch_size, 64, 5, 5) -> (batch_size, 1600)\n",
    "        x = self.fc1(x).relu()  # (batch_size, 1600) -> (batch_size, 128)\n",
    "        x = self.fc2(x).softmax()  # (batch_size, 128) -> (batch_size, 10)\n",
    "\n",
    "        return x\n",
    "    \n",
    "    def __call__(self, x): return self.forward(x)\n",
    "\n",
    "    def parameters(self) -> list:\n",
    "        return get_parameters(self.conv1) + get_parameters(self.conv2) + get_parameters(self.fc1) + get_parameters(self.fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SimpleDataLoader(X_train, Y_train, batch_size=64, shuffle=True)\n",
    "test_loader = SimpleDataLoader(X_test, Y_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyConv()\n",
    "optim = SGD(model.parameters(), lr=0.001) # instantiate the optimizer\n",
    "\n",
    "EPOCHS = 20\n",
    "STEPS = 1000 # num of batches per epoch\n",
    "BATCH_SIZE = 64\n",
    "max_batches_per_epoch = math.ceil(len(X_train) / BATCH_SIZE) # handle smaller last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20: 782 Batches (max: 782) | Train Loss: 1.7830 | Test Accuracy: 0.2257 | Time: 101.31s\n",
      "Epoch 2/20: 782 Batches (max: 782) | Train Loss: 1.7200 | Test Accuracy: 0.3329 | Time: 98.13s\n",
      "Epoch 3/20: 782 Batches (max: 782) | Train Loss: 1.6503 | Test Accuracy: 0.4853 | Time: 98.77s\n",
      "Epoch 4/20: 782 Batches (max: 782) | Train Loss: 1.5845 | Test Accuracy: 0.5984 | Time: 99.17s\n",
      "Epoch 5/20: 782 Batches (max: 782) | Train Loss: 1.5091 | Test Accuracy: 0.7537 | Time: 98.47s\n",
      "Epoch 6/20: 782 Batches (max: 782) | Train Loss: 1.4257 | Test Accuracy: 0.8202 | Time: 97.98s\n",
      "Epoch 7/20: 782 Batches (max: 782) | Train Loss: 1.3680 | Test Accuracy: 0.8363 | Time: 97.17s\n",
      "Epoch 8/20: 782 Batches (max: 782) | Train Loss: 1.3344 | Test Accuracy: 0.8448 | Time: 100.21s\n",
      "Epoch 9/20: 782 Batches (max: 782) | Train Loss: 1.3145 | Test Accuracy: 0.8512 | Time: 98.42s\n",
      "Epoch 10/20: 782 Batches (max: 782) | Train Loss: 1.3014 | Test Accuracy: 0.8564 | Time: 98.44s\n",
      "Epoch 11/20: 782 Batches (max: 782) | Train Loss: 1.2819 | Test Accuracy: 0.9171 | Time: 99.48s\n",
      "Epoch 12/20: 782 Batches (max: 782) | Train Loss: 1.2563 | Test Accuracy: 0.9356 | Time: 98.68s\n",
      "Epoch 13/20: 782 Batches (max: 782) | Train Loss: 1.2420 | Test Accuracy: 0.9433 | Time: 102.76s\n",
      "Epoch 14/20: 782 Batches (max: 782) | Train Loss: 1.2292 | Test Accuracy: 0.9481 | Time: 102.98s\n",
      "Epoch 15/20: 782 Batches (max: 782) | Train Loss: 1.2241 | Test Accuracy: 0.9510 | Time: 103.27s\n",
      "Epoch 16/20: 782 Batches (max: 782) | Train Loss: 1.2160 | Test Accuracy: 0.9535 | Time: 100.80s\n",
      "Epoch 17/20: 782 Batches (max: 782) | Train Loss: 1.2120 | Test Accuracy: 0.9564 | Time: 101.49s\n",
      "Epoch 18/20: 782 Batches (max: 782) | Train Loss: 1.2071 | Test Accuracy: 0.9579 | Time: 104.21s\n",
      "Epoch 19/20: 782 Batches (max: 782) | Train Loss: 1.2037 | Test Accuracy: 0.9605 | Time: 103.43s\n",
      "Epoch 20/20: 782 Batches (max: 782) | Train Loss: 1.1996 | Test Accuracy: 0.9614 | Time: 100.46s\n",
      "Total training time: 2005.64s\n"
     ]
    }
   ],
   "source": [
    "total_time = 0.0\n",
    "steps = min(STEPS, max_batches_per_epoch)\n",
    "for epoch in range(EPOCHS):\n",
    "    start = perf_counter()\n",
    "    running_train_loss = 0.0\n",
    "    for step in range(steps):\n",
    "        with Tensor.train():\n",
    "            samp = np.random.randint(0, X_train.shape[0], size=(64))\n",
    "\n",
    "            # get batch and labels\n",
    "            batch = Tensor(X_train[samp], requires_grad=False)\n",
    "            labels = Tensor(Y_train[samp])\n",
    "\n",
    "            out = model(batch) # forward pass\n",
    "            loss = out.sparse_categorical_crossentropy(labels) # calculate loss\n",
    "            optim.zero_grad() # zero out gradients\n",
    "            loss.backward() # backward pass\n",
    "            optim.step() # update weights\n",
    "\n",
    "            running_train_loss += loss.numpy()\n",
    "\n",
    "    train_loss = running_train_loss / STEPS # loss over all batches, over num batches\n",
    "\n",
    "    # test accuracy over the whole dataset\n",
    "    out = model(Tensor(X_test))\n",
    "    pred = out.argmax(axis=1) # get the index of the max value\n",
    "    accuracy = (pred == Tensor(Y_test)).mean().numpy()\n",
    "\n",
    "    elapsed = perf_counter() - start\n",
    "    total_time += elapsed\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: {steps} Batches (max: {max_batches_per_epoch}) | Train Loss: {train_loss:.4f} | Test Accuracy: {accuracy:.4f} | Time: {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Full Run:\n",
    "\n",
    "Best Test Accuracy: 0.9614\n",
    "\n",
    "```\n",
    "Epoch 1/20: 782 Batches (max: 782) | Train Loss: 1.7830 | Test Accuracy: 0.2257 | Time: 101.31s\n",
    "Epoch 2/20: 782 Batches (max: 782) | Train Loss: 1.7200 | Test Accuracy: 0.3329 | Time: 98.13s\n",
    "Epoch 3/20: 782 Batches (max: 782) | Train Loss: 1.6503 | Test Accuracy: 0.4853 | Time: 98.77s\n",
    "Epoch 4/20: 782 Batches (max: 782) | Train Loss: 1.5845 | Test Accuracy: 0.5984 | Time: 99.17s\n",
    "Epoch 5/20: 782 Batches (max: 782) | Train Loss: 1.5091 | Test Accuracy: 0.7537 | Time: 98.47s\n",
    "Epoch 6/20: 782 Batches (max: 782) | Train Loss: 1.4257 | Test Accuracy: 0.8202 | Time: 97.98s\n",
    "Epoch 7/20: 782 Batches (max: 782) | Train Loss: 1.3680 | Test Accuracy: 0.8363 | Time: 97.17s\n",
    "Epoch 8/20: 782 Batches (max: 782) | Train Loss: 1.3344 | Test Accuracy: 0.8448 | Time: 100.21s\n",
    "Epoch 9/20: 782 Batches (max: 782) | Train Loss: 1.3145 | Test Accuracy: 0.8512 | Time: 98.42s\n",
    "Epoch 10/20: 782 Batches (max: 782) | Train Loss: 1.3014 | Test Accuracy: 0.8564 | Time: 98.44s\n",
    "Epoch 11/20: 782 Batches (max: 782) | Train Loss: 1.2819 | Test Accuracy: 0.9171 | Time: 99.48s\n",
    "Epoch 12/20: 782 Batches (max: 782) | Train Loss: 1.2563 | Test Accuracy: 0.9356 | Time: 98.68s\n",
    "Epoch 13/20: 782 Batches (max: 782) | Train Loss: 1.2420 | Test Accuracy: 0.9433 | Time: 102.76s\n",
    "Epoch 14/20: 782 Batches (max: 782) | Train Loss: 1.2292 | Test Accuracy: 0.9481 | Time: 102.98s\n",
    "Epoch 15/20: 782 Batches (max: 782) | Train Loss: 1.2241 | Test Accuracy: 0.9510 | Time: 103.27s\n",
    "Epoch 16/20: 782 Batches (max: 782) | Train Loss: 1.2160 | Test Accuracy: 0.9535 | Time: 100.80s\n",
    "Epoch 17/20: 782 Batches (max: 782) | Train Loss: 1.2120 | Test Accuracy: 0.9564 | Time: 101.49s\n",
    "Epoch 18/20: 782 Batches (max: 782) | Train Loss: 1.2071 | Test Accuracy: 0.9579 | Time: 104.21s\n",
    "Epoch 19/20: 782 Batches (max: 782) | Train Loss: 1.2037 | Test Accuracy: 0.9605 | Time: 103.43s\n",
    "Epoch 20/20: 782 Batches (max: 782) | Train Loss: 1.1996 | Test Accuracy: 0.9614 | Time: 100.46s\n",
    "Total training time: 2005.64s\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
