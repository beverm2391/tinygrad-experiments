{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['DEBUG'] = '1'\n",
    "\n",
    "import numpy as np\n",
    "from typing import Union\n",
    "import math\n",
    "from time import perf_counter\n",
    "\n",
    "from tinygrad.tensor import Tensor\n",
    "from tinygrad.nn.optim import SGD\n",
    "\n",
    "from lib.utils import get_mnist\n",
    "from lib.dataloader import SimpleDataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, Y_train, X_test, Y_test = get_mnist(\"../data\") # these need to be tensors??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TinyConv:\n",
    "    def __init__(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = SimpleDataLoader(X_train, Y_train, batch_size=64, shuffle=True)\n",
    "test_loader = SimpleDataLoader(X_test, Y_test, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TinyConv()\n",
    "optim = SGD(model.parameters(), lr=0.001) # instantiate the optimizer\n",
    "\n",
    "EPOCHS = 10\n",
    "STEPS = 1000 # num of batches per epoch\n",
    "BATCH_SIZE = 64\n",
    "max_batches_per_epoch = math.ceil(len(X_train) / BATCH_SIZE) # handle smaller last batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_time = 0.0\n",
    "steps = min(STEPS, max_batches_per_epoch)\n",
    "for epoch in range(EPOCHS):\n",
    "    start = perf_counter()\n",
    "    running_train_loss = 0.0\n",
    "    for step in range(steps):\n",
    "        with Tensor.train():\n",
    "            samp = np.random.randint(0, X_train.shape[0], size=(64))\n",
    "\n",
    "            # get batch and labels\n",
    "            batch = Tensor(X_train[samp], requires_grad=False)\n",
    "            labels = Tensor(Y_train[samp])\n",
    "\n",
    "            out = model(batch) # forward pass\n",
    "            loss = out.sparse_categorical_crossentropy(labels) # calculate loss\n",
    "            optim.zero_grad() # zero out gradients\n",
    "            loss.backward() # backward pass\n",
    "            optim.step() # update weights\n",
    "\n",
    "            running_train_loss += loss.numpy()\n",
    "\n",
    "    train_loss = running_train_loss / STEPS # loss over all batches, over num batches\n",
    "\n",
    "    # test accuracy over the whole dataset\n",
    "    out = model(Tensor(X_test))\n",
    "    pred = out.argmax(axis=1) # get the index of the max value\n",
    "    accuracy = (pred == Tensor(Y_test)).mean().numpy()\n",
    "\n",
    "    elapsed = perf_counter() - start\n",
    "    total_time += elapsed\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}: {steps} Batches (max: {max_batches_per_epoch}) | Train Loss: {train_loss:.4f} | Test Accuracy: {accuracy:.4f} | Time: {elapsed:.2f}s\")\n",
    "\n",
    "print(f\"Total training time: {total_time:.2f}s\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
